{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6670f1f1-5c11-4e71-adcd-09d9b0da0dba",
   "metadata": {},
   "source": [
    "# Statistics Introduction Exercises\n",
    "\n",
    "A few basic exercises mostly taken from [here](https://mdonega.github.io/hep-datanalysis-jb/preface.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a63788-67c1-47d4-b495-48cc6b72503e",
   "metadata": {},
   "source": [
    "## Probability and Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726a52a3-02ae-4379-b845-3e0da8c58ef0",
   "metadata": {},
   "source": [
    "1. For each of the following rates (0.1, 0.5, 1, 5) generate 10k events from a Poisson distribution and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfe49b7-69f8-489c-8f31-2239178c0835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c5d04-f1d5-422d-b9e7-a78ece4f694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [0.1, 0.5, 1, 5]\n",
    "repetitions = 10000\n",
    "\n",
    "fig, ax = plt.subplots(1, len(l), figsize=(20, 6))\n",
    "for i, l_ in enumerate(l):\n",
    "    samples = np.random.poisson(l_, repetitions)\n",
    "    ax[i].hist(samples, bins=15, density=True)\n",
    "    ax[i].set_xlim(0, np.max(samples))\n",
    "    ax[i].set_title(f\"$\\lambda$ = {l_}\")\n",
    "    ax[i].set_xlabel(\"r\")\n",
    "    ax[i].set_ylabel(r\"P(x=r)\")\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b6a091-f9be-49f9-953c-1190d116fbbc",
   "metadata": {},
   "source": [
    "2. Draw PDF and CDF (for arbitrary values of their parameters) for the following distributions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e9d552-bc4b-47c6-936f-7df6f55218b2",
   "metadata": {},
   "source": [
    "2. a. gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3ae512-81f0-451d-b156-e3928cb43ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "params = [(0, 0.3), (0, 0.1)]\n",
    "size = 10000\n",
    "limits = (-1, 1)\n",
    "\n",
    "fig, (axf, axF) = plt.subplots(2, 1, figsize=(6,12), sharex=True)\n",
    "for musigma in params:\n",
    "    mu, sigma = musigma\n",
    "    frozen = norm(mu, sigma)\n",
    "    x = np.linspace(*limits, size)\n",
    "    fx = frozen.pdf(x)\n",
    "    Fx = frozen.cdf(x)\n",
    "    axf.plot(x, fx, linestyle=\"-\", label=f\"$\\mu$={mu}, $\\sigma$={sigma}\")\n",
    "    axF.plot(x, Fx, linestyle=\"-\", label=f\"$\\mu$={mu}, $\\sigma$={sigma}\")\n",
    "    axf.legend()\n",
    "    axf.set_xlabel(\"x\")\n",
    "    axF.set_xlabel(\"x\")\n",
    "    axf.set_ylabel(\"f(x)\")\n",
    "    axF.set_ylabel(\"F(x)\")\n",
    "    axf.set_xlim(*limits)\n",
    "    axF.set_xlim(*limits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75215360-30e2-414f-9a1b-d18faea9be67",
   "metadata": {},
   "source": [
    "2. b. $\\chi^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24b4260-117d-4b25-a3b5-6924423ca2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "dofs = [1, 2, 3, 6, 9]\n",
    "size = 10000\n",
    "limits = (0, 10)\n",
    "\n",
    "fig, (axf, axF) = plt.subplots(2, 1, figsize=(6,12), sharex=True)\n",
    "for dof in dofs:\n",
    "    frozen = chi2(dof)\n",
    "    x = np.linspace(*limits, size)\n",
    "    fx = frozen.pdf(x)\n",
    "    Fx = frozen.cdf(x)\n",
    "    axf.plot(x, fx, linestyle=\"-\", label=f\"n={dof}\")\n",
    "    axF.plot(x, Fx, linestyle=\"-\", label=f\"n={dof}\")\n",
    "    axf.legend()\n",
    "    axf.set_xlabel(\"x\")\n",
    "    axF.set_xlabel(\"x\")\n",
    "    axf.set_ylabel(\"f(x)\")\n",
    "    axF.set_ylabel(\"F(x)\")\n",
    "    axf.set_xlim(*limits)\n",
    "    axF.set_xlim(*limits)\n",
    "    axf.set_ylim(0, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82a2c3b-0a38-4ffd-994d-9f2944d0b81b",
   "metadata": {},
   "source": [
    "2. c. Log-normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14da6cb-8025-40d0-989c-3744f1aa09df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import lognorm\n",
    "\n",
    "params = [(0, 0.25), (0, 0.5), (0, 1)]\n",
    "size = 10000\n",
    "limits = (0, 3)\n",
    "\n",
    "fig, (axf, axF) = plt.subplots(2, 1, figsize=(6,12), sharex=True)\n",
    "for musigma in params:\n",
    "    mu, sigma = musigma\n",
    "    frozen = lognorm(s=sigma, scale=np.exp(mu))\n",
    "    x = np.linspace(*limits, size)\n",
    "    fx = frozen.pdf(x)\n",
    "    Fx = frozen.cdf(x)\n",
    "    axf.plot(x, fx, linestyle=\"-\", label=f\"$\\mu$={mu}, $\\sigma$={sigma}\")\n",
    "    axF.plot(x, Fx, linestyle=\"-\", label=f\"$\\mu$={mu}, $\\sigma$={sigma}\")\n",
    "    axf.legend()\n",
    "    axf.set_xlabel(\"x\")\n",
    "    axF.set_xlabel(\"x\")\n",
    "    axf.set_ylabel(\"f(x)\")\n",
    "    axF.set_ylabel(\"F(x)\")\n",
    "    axf.set_xlim(*limits)\n",
    "    axF.set_xlim(*limits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb680aa-55df-4b70-a5b3-5fe23d49389f",
   "metadata": {},
   "source": [
    "3. Visually demonstrate an application of the Central Limit Theorem (CLT): the distribution of the sum of multiple independent uniform random variables tends to a gaussian as more variables are added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323387c3-6cbd-4d85-97e7-db2b5f34bbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "evts = 100000\n",
    "limits = (-2, 2)\n",
    "Ns = list(range(1, 5))\n",
    "\n",
    "sample = np.random.uniform(*limits, (evts, len(Ns)))\n",
    "\n",
    "fig, ax = plt.subplots(1, len(Ns), figsize=(20, 6))\n",
    "for i, N in enumerate(Ns):\n",
    "    mean = np.sum(sample[:, :N], axis=-1)\n",
    "    ax[i].hist(mean, bins=50, range=(-10,10), label=N, density=False)\n",
    "    ax[i].set_title(f\"N={N}\")\n",
    "    ax[i].set_xlabel(\"x\")\n",
    "    ax[i].set_ylabel(\"Number of Events\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c5ce4-d129-4295-a6fe-7485cbd2b8ee",
   "metadata": {},
   "source": [
    "## Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca086c85-e554-41b0-83ae-fbbfdc3abe76",
   "metadata": {},
   "source": [
    "Generate 10k events from a gaussian pdf with $\\mu = 3$ and $\\sigma = 2.3$.\n",
    "Then, define a negative log-likelihood (NLL) and apply the maximum likelihood method (NLL minimization) to find the values $\\hat{\\mu}$ and $\\hat{\\sigma}$ that maximize the likelihood (minimize the NLL). These values are estimators of $\\mu$ and $\\sigma$.\n",
    "Assign an uncertainty to the estimators using the inverse of the hessian around the minimum and the graphic method (values of $\\hat{\\theta}$ for which $\\ln L$ decreases by 0.5).\n",
    "In the graphic method case, reduce the free parameters to only one ($\\mu$) by setting $\\sigma$ to its true value.\n",
    "\n",
    "**Hint**: in the first case, you can minimize the NLL using [scipy.optimize.minimize](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html) and access the inverse of the Hessian using the `hess_inv` method of the result returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4817a973-2c62-4985-b625-308bdd558a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Likelihood:\n",
    "    function: callable\n",
    "    data: np.ndarray\n",
    "\n",
    "    def __call__(self, *params):\n",
    "        return np.prod(self.function(self.data, *params))\n",
    "\n",
    "\n",
    "class NLL(Likelihood):\n",
    "    def __call__(self, *params):\n",
    "        return -np.sum([np.log(self.function(self.data, *params))])\n",
    "\n",
    "def gaussian(x, mu, sigma):\n",
    "    return (\n",
    "        1 / (sigma * np.sqrt(2 * np.pi)) * np.exp(-((x - mu) ** 2) / (2 * sigma ** 2))\n",
    "    )\n",
    "\n",
    "mu_true = 3.0\n",
    "sigma_true = 2.3\n",
    "\n",
    "np.random.seed(42)  # for reproducibility\n",
    "data = np.random.normal(mu_true, sigma_true, size=10_000)\n",
    "\n",
    "nll = NLL(function=gaussian, data=data)\n",
    "\n",
    "initial_guess = [2.0, 1.0]\n",
    "result = minimize(lambda params: nll(*params), x0=initial_guess, method='L-BFGS-B', bounds=[(None, None), (1e-6, None)])\n",
    "\n",
    "if result.success:\n",
    "    mu_hat, sigma_hat = result.x\n",
    "    cov_matrix = result.hess_inv.todense()\n",
    "    mu_hat_unc, sigma_hat_unc = np.sqrt(np.diag(cov_matrix))\n",
    "    print(f\"Estimated mu: {mu_hat:.4f} +/- {mu_hat_unc:.4f}\")\n",
    "    print(f\"Estimated sigma: {sigma_hat:.4f} +/- {sigma_hat_unc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64868037-e683-48ba-8e43-a7209e176770",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mu  = 1000\n",
    "mus = np.linspace(2.9, 3.1, n_mu)\n",
    "\n",
    "nll_scan = np.array([nll(mu, sigma_true) for mu in mus])    \n",
    "idx_min_nll_scan = np.argmin(nll_scan)\n",
    "mu_best = mus[idx_min_nll_scan]\n",
    "nll_scan -= nll_scan[idx_min_nll_scan] # move minimum to 0\n",
    "arr_min_nll_ = np.ones(n_mu)*0.5\n",
    "low_idx, high_idx = np.argwhere(np.diff(np.sign(nll_scan - arr_min_nll_))).flatten()\n",
    "unc = np.abs(mus[high_idx] - mus[low_idx])\n",
    "mu_low = abs(mu_best - mus[low_idx])\n",
    "mu_high = abs(mu_best - mus[high_idx])\n",
    "\n",
    "print(f\"Estimated mu: {mu_best:.4f} +/- {unc/2:.4f}\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "nll_label = r\"$NLL\\left(\\mu | \\vec{x}\\right)$\"\n",
    "ax.plot(mus, nll_scan, label=\"NLL scan\")\n",
    "ax.set_ylim(0, 3)\n",
    "ax.set_ylabel(nll_label)\n",
    "ax.axhline(0.5, color=\"k\", linestyle=\"--\", linewidth=0.5)\n",
    "ax.axvline(mu_best, color=\"k\", linestyle=\"--\", label=r\"$\\mu_{best}$\")\n",
    "ax.axvline(mu_true, color=\"r\", linestyle=\"--\", label=r\"$\\mu_{true}$\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918aef25-1fce-4db9-b11a-3d7212b51e55",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9a5d1b-b350-4c01-b816-1dc5afbed9fd",
   "metadata": {},
   "source": [
    "### Average Body Temperature\n",
    "\n",
    "Consider a population of many adults. A researcher hypothesized that the average adult body temperature is lower than the often-advertised 37 $^\\circ$. That is, the researcher wants an answer to the question: \"Is the average adult body temperature really 37 $^\\circ$? Or is it lower?\".\n",
    "\n",
    "In order to answer the question, he selects a random sample of 100 adults. The average body temperature of the sampled adults is 36.7 degrees, with a standard deviation of 1.4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f1aa9d-7f29-4588-81d3-3742f125f664",
   "metadata": {},
   "source": [
    "#### Part 1\n",
    "\n",
    "What can the reasearcher say about his initial hypothesis?\n",
    "\n",
    "In order to answer, use the following hints and answer these questions:\n",
    "\n",
    "- the test statistic you can use is $t = \\frac{\\bar{x} - \\mu}{s/\\sqrt{n}}$ (where $\\bar{x}$ is the mean of the sample, $\\mu$ is the population mean, $s$ is the standard deviation of the sample and $n$ is the size of the sample), whose PDF is a t-student with $n - 1$ degrees of freedom\n",
    "- what is the null hypothesis? and the alternative?\n",
    "- can the researcher reject the null hypothesis with a significance level of 0.05? and 0.01?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60447c6-3a40-4fac-815d-a7d218915f1c",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "\n",
    "This is the simplest case of hypothesis test, in which we want to use the data that we collected to make a statement about a certain model that is supposed to be the true one (i.e. the **null hypothesis**). To do this we need some ingredients:\n",
    "\n",
    "- test statistic (a function of the data), given above;\n",
    "- the PDF followed by the test statistic in case the null hypothesis is valid; one can have the analytical form (part 1) or sample it (part 2);\n",
    "- a significance level (**decided by us!**) at which we want to exclude the null hypothesis (0.05 and 0.01 in our case).\n",
    "\n",
    "Using the test statistic applied to the data we gathered and the PDF of the test statistic for the null hypothesis we can compute the **p-value** of our data, defined as the probability (under null hypothesis) of obtaining a result equal to or more extreme than what was actually observed. If the p-value is lower than the significance level we chose, we can say that we can **exclude** the null hypothesis at that significance level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8785edb2-fb93-465d-936e-d4e9543dbe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, t\n",
    "from scipy.integrate import quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f12344a-605c-4a34-bb77-ce320ea86837",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_null = 37\n",
    "\n",
    "n_sample = 100\n",
    "mu_sample = 36.7\n",
    "std_sample = 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d67115a-2480-4b65-964f-22fbb158d525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_statistic(x, mu, s, n):\n",
    "    return (x - mu) / (s / np.sqrt(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f51142-7c86-4581-88f3-b63209a4e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_ts = test_statistic(mu_sample, mu_null, std_sample, n_sample)\n",
    "print(f\"t_obs = {observed_ts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50844692-7f36-4201-8023-f20ac0c154bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check multiple values of TS to see in which direction we have \"more extreme results\"\n",
    "test_temp = np.array([40, 39, 37, 36.5, 35, 31])\n",
    "print(test_statistic(test_temp, mu_null, std_sample, n_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8404392a-236d-4f4a-98bd-f7c2e8e63f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen = t(n_sample - 1)\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "y = frozen.pdf(x)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "ax.plot(x, y)\n",
    "ax.axvline(observed_ts, color=\"red\")\n",
    "ax.set_xlabel(\"t\")\n",
    "ax.set_ylabel(\"f(x)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea44e970-04dc-4739-b42e-66800b2b84b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value, _ = quad(frozen.pdf, -np.inf, observed_ts)\n",
    "print(f\"p-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9057a5-481b-4e67-b588-035213b3e259",
   "metadata": {},
   "source": [
    "Can the null hypothesys be rejected with a significance level of 5% (CL of 95%)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c119d88-8e21-4b10-939d-7f7d504ca196",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value < 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dbfdbd-b8bb-4830-8c5e-01ae28eb3c76",
   "metadata": {},
   "source": [
    "Can the null hypothesys be rejected with a significance level of 1% (CL of 99%)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fa1c9b-2f00-4ae1-a3d9-08c1618b9a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value < 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33a8c03-7a90-42d1-89fd-d0658e988e21",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Part 2\n",
    "\n",
    "Repeat the exercise, but instead of using the t-student PDF sample the distribution from what you know about the null hypothesis. You can consider the temperature of the population following a gaussian distribution with mean 37 (as stated above) and standard deviation 0.4 (one of the values found in medical literature)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9281d05-3e9a-4dab-812f-eb2776443d11",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "\n",
    "In order to sample the distribution followed by the test statistic in case of null hypothesis, we need to throw a (possibly large) number of **toy experiments** and use the test statistic computed on each of them to *fill a histogram*. That histogram will be the sampled PDF that we are looking for.\n",
    "\n",
    "How can each toy experiment be simulated? The answer is in the question: sample a number ```toy_size``` of events (people, in this case) which is **equal to the data sample aquired** from a gaussian distribution with mean 37 and standard deviation 0.4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39be8e28-4597-4c06-8da5-3c88b4bdfb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_null = 37\n",
    "sigma_null = 0.4\n",
    "\n",
    "toy_size = 100\n",
    "n_toys = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e820d2b-ef7a-485c-af00-2ac2d4cd3e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows = elements in one toy\n",
    "# columns = how many toys\n",
    "samples = np.random.normal(mu_null, sigma_null, size=(toy_size, n_toys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5286cb9a-ea1a-4dbc-8b5b-ab50dede0116",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(samples, axis=0)\n",
    "stds = np.std(samples, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ff3b45-c5df-45e7-a18e-e64d5a8a6daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_statistics = test_statistic(means, mu_null, stds, toy_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ff6895-bab9-4847-b24a-66f3d118c008",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "ax.axvline(observed_ts, color=\"red\")\n",
    "ax.hist(test_statistics, bins=100, range=(min(test_statistics), max(test_statistics)), density=True)\n",
    "ax.set_xlabel(\"t\")\n",
    "ax.set_ylabel(\"f(x)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6100bd06-8112-4969-9fee-b358a13a4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = len(test_statistics[test_statistics < observed_ts]) / len(test_statistics)\n",
    "print(f\"p-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0800f2-29f2-4150-aa8c-1683a3affe36",
   "metadata": {},
   "source": [
    "As expected, the two methods give very similar result. In general, the first method is of course faster, but we can use it only if the pdf of the test statistics is known. When this does not happen, we need to sample it with the second method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd43619-c519-447e-b6c4-f608130434d3",
   "metadata": {},
   "source": [
    "### Coin\n",
    "\n",
    "We suspect a coin might be biased towards heads. We thus toss the coin n = 10 times and observe X = 8. \n",
    "Based on this experiment, what can we say about the fairness of the coin?\n",
    "**Hint**: use a binomial to model the pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408d1ea7-7e69-4cd2-9f6e-a611eb62c1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "n = 10\n",
    "x = 8\n",
    "p_null = 0.5\n",
    "\n",
    "# Compute the p-value: P(X >= 8) under H0\n",
    "# This is the survival function: P(X >= x) = sf(x - 1)\n",
    "p_value = binom.sf(x - 1, n, p_null)\n",
    "\n",
    "print(f\"P-value for testing p > 0.5: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
