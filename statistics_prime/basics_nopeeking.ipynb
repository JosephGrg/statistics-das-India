{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6670f1f1-5c11-4e71-adcd-09d9b0da0dba",
   "metadata": {},
   "source": [
    "# Statistics Introduction Exercises\n",
    "\n",
    "A few basic exercises mostly taken from [here](https://mdonega.github.io/hep-datanalysis-jb/preface.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a63788-67c1-47d4-b495-48cc6b72503e",
   "metadata": {},
   "source": [
    "## Probability and Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726a52a3-02ae-4379-b845-3e0da8c58ef0",
   "metadata": {},
   "source": [
    "1. For each of the following rates (0.1, 0.5, 1, 5) generate 10k events from a Poisson distribution and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfe49b7-69f8-489c-8f31-2239178c0835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c5d04-f1d5-422d-b9e7-a78ece4f694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [0.1, 0.5, 1, 5]\n",
    "repetitions = 10000\n",
    "\n",
    "fig, ax = plt.subplots(1, len(l), figsize=(20, 6))\n",
    "for i, l_ in enumerate(l):\n",
    "    samples = np.random.poisson(l_, repetitions)\n",
    "    ax[i].hist(samples, bins=15, density=True)\n",
    "    ax[i].set_xlim(0, np.max(samples))\n",
    "    ax[i].set_title(f\"$\\lambda$ = {l_}\")\n",
    "    ax[i].set_xlabel(\"r\")\n",
    "    ax[i].set_ylabel(r\"P(x=r)\")\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b6a091-f9be-49f9-953c-1190d116fbbc",
   "metadata": {},
   "source": [
    "2. Draw PDF and CDF (for arbitrary values of their parameters) for the following distributions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e9d552-bc4b-47c6-936f-7df6f55218b2",
   "metadata": {},
   "source": [
    "2. a. gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3ae512-81f0-451d-b156-e3928cb43ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "params = [(0, 0.3), (0, 0.1)]\n",
    "size = 10000\n",
    "limits = (-1, 1)\n",
    "\n",
    "fig, (axf, axF) = plt.subplots(2, 1, figsize=(6,12), sharex=True)\n",
    "for musigma in params:\n",
    "    mu, sigma = musigma\n",
    "    frozen = norm(mu, sigma)\n",
    "    x = np.linspace(*limits, size)\n",
    "    fx = frozen.pdf(x)\n",
    "    Fx = frozen.cdf(x)\n",
    "    axf.plot(x, fx, linestyle=\"-\", label=f\"$\\mu$={mu}, $\\sigma$={sigma}\")\n",
    "    axF.plot(x, Fx, linestyle=\"-\", label=f\"$\\mu$={mu}, $\\sigma$={sigma}\")\n",
    "    axf.legend()\n",
    "    axf.set_xlabel(\"x\")\n",
    "    axF.set_xlabel(\"x\")\n",
    "    axf.set_ylabel(\"f(x)\")\n",
    "    axF.set_ylabel(\"F(x)\")\n",
    "    axf.set_xlim(*limits)\n",
    "    axF.set_xlim(*limits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75215360-30e2-414f-9a1b-d18faea9be67",
   "metadata": {},
   "source": [
    "2. b. $\\chi^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24b4260-117d-4b25-a3b5-6924423ca2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "dofs = [1, 2, 3, 6, 9]\n",
    "size = 10000\n",
    "limits = (0, 10)\n",
    "\n",
    "fig, (axf, axF) = plt.subplots(2, 1, figsize=(6,12), sharex=True)\n",
    "for dof in dofs:\n",
    "    frozen = chi2(dof)\n",
    "    x = np.linspace(*limits, size)\n",
    "    fx = frozen.pdf(x)\n",
    "    Fx = frozen.cdf(x)\n",
    "    axf.plot(x, fx, linestyle=\"-\", label=f\"n={dof}\")\n",
    "    axF.plot(x, Fx, linestyle=\"-\", label=f\"n={dof}\")\n",
    "    axf.legend()\n",
    "    axf.set_xlabel(\"x\")\n",
    "    axF.set_xlabel(\"x\")\n",
    "    axf.set_ylabel(\"f(x)\")\n",
    "    axF.set_ylabel(\"F(x)\")\n",
    "    axf.set_xlim(*limits)\n",
    "    axF.set_xlim(*limits)\n",
    "    axf.set_ylim(0, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82a2c3b-0a38-4ffd-994d-9f2944d0b81b",
   "metadata": {},
   "source": [
    "2. c. Log-normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14da6cb-8025-40d0-989c-3744f1aa09df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import lognorm\n",
    "\n",
    "params = [(0, 0.25), (0, 0.5), (0, 1)]\n",
    "size = 10000\n",
    "limits = (0, 3)\n",
    "\n",
    "fig, (axf, axF) = plt.subplots(2, 1, figsize=(6,12), sharex=True)\n",
    "for musigma in params:\n",
    "    mu, sigma = musigma\n",
    "    frozen = lognorm(s=sigma, scale=np.exp(mu))\n",
    "    x = np.linspace(*limits, size)\n",
    "    fx = frozen.pdf(x)\n",
    "    Fx = frozen.cdf(x)\n",
    "    axf.plot(x, fx, linestyle=\"-\", label=f\"$\\mu$={mu}, $\\sigma$={sigma}\")\n",
    "    axF.plot(x, Fx, linestyle=\"-\", label=f\"$\\mu$={mu}, $\\sigma$={sigma}\")\n",
    "    axf.legend()\n",
    "    axf.set_xlabel(\"x\")\n",
    "    axF.set_xlabel(\"x\")\n",
    "    axf.set_ylabel(\"f(x)\")\n",
    "    axF.set_ylabel(\"F(x)\")\n",
    "    axf.set_xlim(*limits)\n",
    "    axF.set_xlim(*limits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb680aa-55df-4b70-a5b3-5fe23d49389f",
   "metadata": {},
   "source": [
    "3. Visually demonstrate an application of the Central Limit Theorem (CLT): the distribution of the sum of multiple independent uniform random variables tends to a gaussian as more variables are added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323387c3-6cbd-4d85-97e7-db2b5f34bbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "evts = 100000\n",
    "limits = (-2, 2)\n",
    "Ns = list(range(1, 5))\n",
    "\n",
    "sample = np.random.uniform(*limits, (evts, len(Ns)))\n",
    "\n",
    "fig, ax = plt.subplots(1, len(Ns), figsize=(20, 6))\n",
    "for i, N in enumerate(Ns):\n",
    "    mean = np.sum(sample[:, :N], axis=-1)\n",
    "    ax[i].hist(mean, bins=50, range=(-10,10), label=N, density=False)\n",
    "    ax[i].set_title(f\"N={N}\")\n",
    "    ax[i].set_xlabel(\"x\")\n",
    "    ax[i].set_ylabel(\"Number of Events\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c5ce4-d129-4295-a6fe-7485cbd2b8ee",
   "metadata": {},
   "source": [
    "## Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca086c85-e554-41b0-83ae-fbbfdc3abe76",
   "metadata": {},
   "source": [
    "Generate 10k events from a gaussian pdf with $\\mu = 3$ and $\\sigma = 2.3$.\n",
    "Then, define a negative log-likelihood (NLL) and apply the maximum likelihood method (NLL minimization) to find the values $\\hat{\\mu}$ and $\\hat{\\sigma}$ that maximize the likelihood (minimize the NLL). These values are estimators of $\\mu$ and $\\sigma$.\n",
    "Assign an uncertainty to the estimators using the inverse of the hessian around the minimum and the graphic method (values of $\\hat{\\theta}$ for which $\\ln L$ decreases by 0.5).\n",
    "\n",
    "**Hint**: in the first case, you can minimize the NLL using [scipy.optimize.minimize](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html) and access the inverse of the Hessian using the `hess_inv` method of the result returned; in the second case, for the sake of the exercise, when you \"scan\" a parameter, you can either fix the other parameter to its true value or profile it (i.e., find the value that minimizes the NLL for that value of the scanned parameter). Note that the correct procedure would require to profile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4817a973-2c62-4985-b625-308bdd558a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Likelihood:\n",
    "    function: callable\n",
    "    data: np.ndarray\n",
    "\n",
    "    def __call__(self, *params):\n",
    "        return np.prod(self.function(self.data, *params))\n",
    "\n",
    "\n",
    "class NLL(Likelihood):\n",
    "    def __call__(self, *params):\n",
    "        return -np.sum([np.log(self.function(self.data, *params))])\n",
    "\n",
    "def gaussian(x, mu, sigma):\n",
    "    return (\n",
    "        1 / (sigma * np.sqrt(2 * np.pi)) * np.exp(-((x - mu) ** 2) / (2 * sigma ** 2))\n",
    "    )\n",
    "\n",
    "mu_true = 3.0\n",
    "sigma_true = 2.3\n",
    "\n",
    "np.random.seed(42)  # for reproducibility\n",
    "data = np.random.normal(mu_true, sigma_true, size=10_000)\n",
    "\n",
    "nll = NLL(function=gaussian, data=data)\n",
    "\n",
    "initial_guess = [2.0, 1.0]\n",
    "result = minimize(lambda params: nll(*params), x0=initial_guess, method='L-BFGS-B', bounds=[(None, None), (1e-6, None)])\n",
    "\n",
    "if result.success:\n",
    "    mu_hat, sigma_hat = result.x\n",
    "    cov_matrix = result.hess_inv.todense()\n",
    "    mu_hat_unc, sigma_hat_unc = np.sqrt(np.diag(cov_matrix))\n",
    "    print(f\"Estimated mu: {mu_hat:.4f} +/- {mu_hat_unc:.4f}\")\n",
    "    print(f\"Estimated sigma: {sigma_hat:.4f} +/- {sigma_hat_unc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64868037-e683-48ba-8e43-a7209e176770",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mu  = 1000\n",
    "mus = np.linspace(2.9, 3.1, n_mu)\n",
    "\n",
    "#nll_scan = np.array([nll(mu, sigma_true) for mu in mus])\n",
    "nll_scan = []\n",
    "for mu in mus:\n",
    "    initial_guess = 2.\n",
    "    def _gaussian(x, sigma):\n",
    "        return 1 / (sigma * np.sqrt(2 * np.pi)) * np.exp(-((x - mu) ** 2) / (2 * sigma ** 2))\n",
    "    _nll = NLL(_gaussian, data)\n",
    "    result = minimize(lambda params: _nll(*params), x0=initial_guess, method='L-BFGS-B', bounds=[(1e-6, None)])\n",
    "    nll_scan.append(result.fun)\n",
    "    \n",
    "idx_min_nll_scan = np.argmin(nll_scan)\n",
    "mu_best = mus[idx_min_nll_scan]\n",
    "nll_scan -= nll_scan[idx_min_nll_scan] # move minimum to 0\n",
    "arr_min_nll_ = np.ones(n_mu)*0.5\n",
    "low_idx, high_idx = np.argwhere(np.diff(np.sign(nll_scan - arr_min_nll_))).flatten()\n",
    "unc = np.abs(mus[high_idx] - mus[low_idx])\n",
    "mu_low = abs(mu_best - mus[low_idx])\n",
    "mu_high = abs(mu_best - mus[high_idx])\n",
    "\n",
    "print(f\"Estimated mu: {mu_best:.4f} +/- {unc/2:.4f}\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "nll_label = r\"$NLL\\left(\\mu | \\vec{x}\\right)$\"\n",
    "ax.plot(mus, nll_scan, label=\"NLL scan\")\n",
    "ax.set_ylim(0, 3)\n",
    "ax.set_ylabel(nll_label)\n",
    "ax.axhline(0.5, color=\"k\", linestyle=\"--\", linewidth=0.5)\n",
    "ax.axvline(mu_best, color=\"k\", linestyle=\"--\", label=r\"$\\mu_{best}$\")\n",
    "ax.axvline(mu_true, color=\"r\", linestyle=\"--\", label=r\"$\\mu_{true}$\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918aef25-1fce-4db9-b11a-3d7212b51e55",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd43619-c519-447e-b6c4-f608130434d3",
   "metadata": {},
   "source": [
    "We suspect a coin might be biased towards heads. We thus toss the coin n = 10 times and observe X = 8. \n",
    "Based on this experiment, what can we say about the fairness of the coin?\n",
    "**Hint**: use a binomial to model the pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408d1ea7-7e69-4cd2-9f6e-a611eb62c1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "n = 10\n",
    "x = 8\n",
    "p_null = 0.5\n",
    "\n",
    "# Compute the p-value: P(X >= 8) under H0\n",
    "# This is the survival function: P(X >= x) = sf(x - 1)\n",
    "p_value = binom.sf(x - 1, n, p_null)\n",
    "\n",
    "print(f\"P-value for testing p > 0.5: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
