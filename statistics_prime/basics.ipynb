{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6670f1f1-5c11-4e71-adcd-09d9b0da0dba",
   "metadata": {},
   "source": [
    "# Statistics Introduction Exercises\n",
    "\n",
    "A few basic exercises mostly taken from [here](https://mdonega.github.io/hep-datanalysis-jb/preface.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a63788-67c1-47d4-b495-48cc6b72503e",
   "metadata": {},
   "source": [
    "## Probability and Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726a52a3-02ae-4379-b845-3e0da8c58ef0",
   "metadata": {},
   "source": [
    "1. For each of the following rates (0.1, 0.5, 1, 5) generate 10k events from a Poisson distribution and plot it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b6a091-f9be-49f9-953c-1190d116fbbc",
   "metadata": {},
   "source": [
    "2. Draw PDF and CDF (for arbitrary values of their parameters) for the following distributions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e9d552-bc4b-47c6-936f-7df6f55218b2",
   "metadata": {},
   "source": [
    "2. a. gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75215360-30e2-414f-9a1b-d18faea9be67",
   "metadata": {},
   "source": [
    "2. b. $\\chi^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82a2c3b-0a38-4ffd-994d-9f2944d0b81b",
   "metadata": {},
   "source": [
    "2. c. Log-normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb680aa-55df-4b70-a5b3-5fe23d49389f",
   "metadata": {},
   "source": [
    "3. Visually demonstrate an application of the Central Limit Theorem (CLT): the distribution of the sum of multiple independent uniform random variables tends to a gaussian as more variables are added."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c5ce4-d129-4295-a6fe-7485cbd2b8ee",
   "metadata": {},
   "source": [
    "## Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca086c85-e554-41b0-83ae-fbbfdc3abe76",
   "metadata": {},
   "source": [
    "Generate 10k events from a gaussian pdf with $\\mu = 3$ and $\\sigma = 2.3$.\n",
    "Then, define a negative log-likelihood (NLL) and apply the maximum likelihood method (NLL minimization) to find the values $\\hat{\\mu}$ and $\\hat{\\sigma}$ that maximize the likelihood (minimize the NLL). These values are estimators of $\\mu$ and $\\sigma$.\n",
    "Assign an uncertainty to the estimators using the inverse of the hessian around the minimum and the graphic method (values of $\\hat{\\theta}$ for which $\\ln L$ decreases by 0.5).\n",
    "\n",
    "**Hint**: in the first case, you can minimize the NLL using [scipy.optimize.minimize](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html) and access the inverse of the Hessian using the `hess_inv` method of the result returned; in the second case, for the sake of the exercise, when you \"scan\" a parameter, you can either fix the other parameter to its true value or profile it (i.e., find the value that minimizes the NLL for that value of the scanned parameter). Note that the correct procedure would require to profile it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918aef25-1fce-4db9-b11a-3d7212b51e55",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd43619-c519-447e-b6c4-f608130434d3",
   "metadata": {},
   "source": [
    "We suspect a coin might be biased towards heads. We thus toss the coin n = 10 times and observe X = 8. \n",
    "Based on this experiment, what can we say about the fairness of the coin?\n",
    "**Hint**: use a binomial to model the pdf."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
